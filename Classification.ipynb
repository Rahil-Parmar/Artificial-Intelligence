{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du8PlGJLFinE"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearDiscriminantAnalysis:\n",
        "  def __init__(self,components):\n",
        "    self.components = components\n",
        "    self.ld = None\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    features = X.shape[1]\n",
        "    sep_within = np.zeros((features,features))\n",
        "    sep_between = np.zeros((features,features))\n",
        "    distinct_labels = np.unique(y)\n",
        "    total_mean = np.mean(X,axis = 0)\n",
        "    \n",
        "    for i in distinct_labels:\n",
        "      input = X[y==i]\n",
        "      mean = np.mean(input,axis = 0)\n",
        "      sep_within += np.dot((input-mean).T,(input-mean))\n",
        "      number_of_sample = input.shape[0]\n",
        "      mean_difference = (mean-total_mean).reshape(features,1)\n",
        "      sep_between += input.shape[0]*np.dot(mean_difference,mean_difference.T)\n",
        "\n",
        "    A = np.dot(np.linalg.inv(sep_within),sep_between)\n",
        "    eigenvalues , eigenvectors = np.linalg.eig(A)\n",
        "    eigenvectors = eigenvectors.T\n",
        "    i = np.argsort(abs(eigenvalues))[::-1]\n",
        "    eigenvector = eigenvectors[i]\n",
        "    eigenvalues = eigenvalues[i]\n",
        "    self.ld = eigenvectors[:self.components] \n",
        "\n",
        "  def predict(self,X):\n",
        "    return np.dot(X,self.ld.T)\n",
        "\n",
        "class NaiveBayes():\n",
        "  def fit(self,X,y):\n",
        "    samples,features = X.shape\n",
        "    self.labels = np.unique(y)\n",
        "    self.mean = np.zeros((len(self.labels),features),dtype=np.float64)\n",
        "    self.variance = np.zeros((len(self.labels),features),dtype=np.float64)\n",
        "    self.prior_prob = np.zeros(len(self.labels),dtype=np.float64)\n",
        "    # print(self.mean)\n",
        "    for x in self.labels:\n",
        "      inp = X[y==x]\n",
        "      self.mean[x,:] = inp.mean(axis = 0)\n",
        "      self.variance[x,:] = inp.var(axis = 0)\n",
        "      self.prior_prob[x] = inp.shape[0]/float(samples)\n",
        "\n",
        "  def posterior(self,X):\n",
        "    posterior_probability = []\n",
        "    for i,x in enumerate(self.labels):\n",
        "        prior = np.log(self.prior_prob[i])\n",
        "        posterior = np.sum(np.log(self.Gaussian(i, X)))\n",
        "        posterior = prior + posterior\n",
        "        posterior_probability.append(posterior)\n",
        "    return self.labels[np.argmax(posterior_probability)]\n",
        "  \n",
        "  def Gaussian(self, class_i, x):\n",
        "    mean = self.mean[class_i]\n",
        "    # print(mean)\n",
        "    var = self.variance[class_i]\n",
        "    return (np.exp(-((x - mean) ** 2) / (2 * var))) / (np.sqrt(2 * np.pi * var))\n",
        "\n",
        "  def predict(self,X):\n",
        "    return np.array([self.posterior(x) for x in X])\n",
        "\n",
        "class LogisticRegression():\n",
        "  def fit(self,X,y,alpha = 0.01,steps = 100):\n",
        "    samples,features = X.shape\n",
        "    self.weights = np.zeros(features+1)\n",
        "    data = np.hstack((X,np.ones((X.shape[0],1))))\n",
        "    for i in range(steps):\n",
        "      predicted = 1/(1+np.exp(-np.dot(data,self.weights)))\n",
        "      dw = np.dot(np.dot(data.T,(predicted-y)),np.dot(predicted,(1-predicted)))\n",
        "      self.weights -= alpha*dw\n",
        "  \n",
        "  def predict(self,X):\n",
        "    target = 1/(1+np.exp(-np.dot(np.hstack((X,np.ones((X.shape[0],1)))),self.weights)))\n",
        "    target = np.where(target>0.5,1,0)\n",
        "    return target\n",
        "\n",
        "def mean_squared(target,predicted):\n",
        "  return 1-np.square(np.subtract(target,predicted)).mean()"
      ],
      "metadata": {
        "id": "floOLFgxGkxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}